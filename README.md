# tick-tack-toe-ai
научно-исследовательская работа на тему "искусственный интеллект"

автор: Батятин Максим (DevMule)

github: https://github.com/DevMule/tick-tack-toe-ai

цель работы: исследовать процессы проектирования и создания автоматических систем для решения конкретных задач

Я пытался выбрать для проекта простую, знакомую каждому основу что позволит мне, разрабатывая ботов, 
долгое время не доходить до состояния нераспутываемого хаоса. Мой выбор пал на древнюю игру - "херики-оники".
Прежде чем начать разрабатывать ботов, необходимо создать основу для игры.

# Игровое поле
Это оказалось нетрудно, т.к. по сути игра представляет из себя массив со значениями для каждой ячейки и функцию проверки на победу.
Другое дело - я понятия не имел чем буду ограничиваться в будущем, ведь правил и видов крестиков-ноликов есть довольно большое количество, потому исходя из этого и имеющихся на данным момент привычек сделал систему "резиновой" - поле и условие победы может быть разных размеров. **[код игрового поля - класс Desk](https://github.com/DevMule/tick-tack-toe-ai/blob/master/desk/desk.py)**

Хорошо! Доска есть, теперь нужно сделать так, чтобы в неё можно было хотя бы играть. Нужно сделать реффери, который будет запрашивать ход у игроков и универсальный интерфейс от которого будут наследоваться игроки во имя полиморфизма!

Реффери - верхушка архитектуры программы. Он должен взаимодействовать с игроками и игровым полем. Для каждой игры, Реффери обнуляет доску и ведёт игру до тех пор, пока не объявит победителя или пока не законится место на доске. По завершении игры, реффери отправляет игрокам историю и состояние игры. История необходима для обучающихся ботов т.к. оценить каждый отдельный шаг в игре можно только после её завершения. **[код класса Referee](https://github.com/DevMule/tick-tack-toe-ai/blob/master/referee.py)**

Контроллер содержит в себе интерфейс, с которым взаимодействует реффери.
**[код класса Controller](https://github.com/DevMule/tick-tack-toe-ai/blob/master/bots_and_uis/controller.py)**

# Игроки
Под игроками я подразумеваю системы, которые будут взаимодействовать с игрой как игроки. Это боты и пользовательские интерфейсы, но никак не люди. Все игроки наследуются от класса ```Controller``` для удобного взаимодействия с игрой. В перспективе Контроллер можно расширять не только ботами и консольным интерфейсом, а даже например интерфейсом для взаимодействия с удалённым игроком через веб-сокеты :)

Ничего не мешает создать веб-страничку для удобного набора опыта игры с людьми)

## 1. консольный пользовательский интерфейс
Единственный способ заимодействия программ с человеком на данный момент.
Благодаря Реффери в крестики-нолики играть могут два человека одновременно, более того это даже выглядит прилично на экране)

![интерфейс](https://image.prntscr.com/image/Yu_Y7n9zSzatuu78gA-CrQ.png)

## 2. рандомный бот
Просто расширяет у контроллера метод хода, выдаёт случайную свободную координату. Это самый скучный и самый лёгкий игрок, 
однако даже он благодаря своей удаче иногда побеждает minimax бота :) 

## 3. minimax бот
Более комплексная машина, но тоже представляет из себя только расширение метода совершения хода
Суть его содержания [понятна уже из названия](https://www.youtube.com/watch?v=KU9Ch59-4vw): Он строит всё дерево возможных ходов и выбирает из них самый ближайший ход для победы или, если победа невозможна, для ничьи.
Его победить довольно сложно, однако возможно, расставляя подобные ловушки:

![ловушка джокера](https://image.prntscr.com/image/cPHTPBs8TBq2sQ1GhqOfIA.png)

Хотя, как понятно из скриншота, minimax бот сам тоже умеет их расставлять :)

Суть минимакс алгоритма для игры в крестики-нолики:
Корневым узлом является состояние игры вданный момент. Бот рекурсивно строит дерево с узлами - возможными исходами игры для каждого хода. Если состояние игры для узла завершённое - есть победитель или объявлена ничья, то узел является терминальным - он имеет своё значение по умолчанию. Значение терминального узла зависит от состояния игры: сходивший выиграл = 1, никто не выиграл = 0.
Далее, при каждом шаге обратной рекурсии, неретминальные узлы приобретают своё значение - если учитывается ход бота, то берётся максимальное из значений дочерних узлов, если ход врага, то минимальное. 
При каждом шаге обратной рекурсии, значения узлов умножаются на "-1", т.к. игроки меняются поочерёдно.
Бот в приоритете выбирает ход с максимальным значением

![дерево](https://static.javatpoint.com/tutorial/ai/images/mini-max-algorithm-in-ai-step1.png)

## 4. бот на нейросети
Самый сложный в плане реализации бот, для его реализации необходимо было изучить некоторую литературу, я лично пользовался следующей:
[видос на ютубе по TensorFlow](https://www.youtube.com/watch?v=6g4O5UOH304), однако я пытался писать бота без специальных библиотек и 
[туториал по нейросетям для начинающих](https://python-scripts.com/intro-to-neural-networks), отсюда я взял некоторый код,

Тема очень сложная и для создания бота пришлось очень сильно декомпозировать поставленные задачи:
### шаг №1 Нейроны и веса
"Мозг" такого бота должен состоять из сети послойно соединённых между собой нейронов. Каждый нейрон имеет коэффициент веса для каждого входящего сигнала (красный на картинке), плюс общее значение сдвига - bias (зелёный на картинке). Но т.к. сигнал нейрона должен иметь значение от 0 до 1, то после общее значение нейрона проходит через функцию сигмоиды (желтая). Bias сдесь - своеобразный "нормализатор" значения. Для нейрона был создан класс ```Neuron```

У класса ```Neuron``` реализован метод рассчёта сигнала - ```Neuron.feedforward()```, который выполняет вышеуказанные рассчёты и возвращает значение.

![нейрон](https://python-scripts.com/wp-content/webp-express/webp-images/uploads/2019/10/neural-networks-1.jpg.webp)

### шаг №2 Сбор нейронов в нейросеть:
Структура моей нейросети будет трёхслойной: **Первый слой - входные узлы** - их количество равно количеству ячеек в игровом поле. Т.к. ранее я реализовал доску таким образом, что технически в ячейках содержаться цифры, значения ячеек будем сразу передавать во входные узлы. **Второй слой - скрытый** - размер такого слоя может быть каким угодно. Семантика этих узлов максимально абстрактна, иными словами каждый из этих узлов несёт в себе какой-то конкретный смысл, но никто не может знать какой именно :) Количество скрытых узлов подбирается "на ощупь". **Третий слой - выходные узлы** - Их количество в моём случае тоже будет равно количеству ячеек в игровом поле, а их значения будут представлять из себя "вес" пользы каждого хода. ~~Сам выбор хода я реализовал как рандомный выбор с шансом, равным для каждого варианта соотношению: (вес варианта / суммарный вес всех вариантов)~~ UPD 18.01.2020: Выбирается ход с наибольшим значением, это даёт бо́льшую гибкость при обучении - достаточно будет немного изменить вес нейрона чтобы получить нужное значение при этом сильно не меняя веса для других нейронов.

Нейроны объединяются в сеть при инициализации класса ```NeuralNetworkBot```. Отлично! Нейросеть готова и при правильных весах и сдвигах в каждом нейроне, она будет выдавать наиболее оптимальный путь. Осталось дело за малым - написать функцию тренировки сети...

### шаг №3 Тренировка нейросети:
Для начала необходимо понять суть тренировки. Какие именно процессы должны происходить при тренировке сети? Какие данные необходимы при этом?

Для тренировки необходимы существующие данные с некоторой оценкой ходов. Например:

![пример данных для обучения](https://image.prntscr.com/image/e7ijLJViQdeeyimObY8i0Q.png)

Имея на руках конкретные значения для входных и выходных нейронов, можно посчитать изменения для всех весов и сдвигов, необходимые для лучшего соответствия данным выходам. В этой части очень много высшей математики, но основная теория разжёвана в [этом туториале](https://python-scripts.com/intro-to-neural-networks).

В ```NeuralNetworkBot``` тренировка происходит по вызову функции ```NeuralNetworkBot.train(inputs, outputs)``` вызывается после завершения игры, в процессе чего бот учится играть как победитель и отучивается играть как проигравший. 

UPD 19.01.2020: Заметил что эта функция переписывает веса не только последних ходов, но и первых, что нехорошо, потому что бот ходит так, как считает правильным и постоянное переписывание "правильного" опыта в итоге затянет обучение в разы, потому сделал так, что чем ближе состояние истории игры к концу, тем сильнее коэффициент изменения весов.

Для набора опыта создал [специальный файл](https://github.com/DevMule/tick-tack-toe-ai/blob/master/learn_bot.py), в котором нейросеть играет сама с собой. Переменная ```epochs```, которую я реализовал внутри бота теперь не нужна, так как её заменяет количество игр, в которые играет бот.

# Вывод:
Сравнив ботов, могу выделить для каждого бота следующее:

**Рандомный бот** не занимает памяти, процесс хода происходит быстро, т.к. никаких сложных рассчётов он не делает. С начала я хотел учить нейросетевого бота игрой двух рандомных, что должно было дать как можно более разнообразный опыт, но такой опыт вряд ли будет включать в себя хитрые ходы вроде ловушек с двумя возможными ходами для победы - довольно малая вероятность.

**Минимакс бот** не занимает памяти, все рассчёты проводит исходя из данного ему состояния игрового поля. Если размеры поля увеличить, то время на "раздумье" этого бота увеличится в геометрической прогрессии, что делает почти невозможным в таком случае игру на большой доске. Можно, конечно, создать боту хранилище состояний, которые он будет проссчитывать только один раз, это увеличит скорость игры. Но при том всё равно на больших досках будет занимать очень много времени первый рассчёт.

**Бот на нейросети** Занимает минимум памяти, все рассчёты происходят очень быстро, т.к. по сути представлют из себя иттеративные арифметические операции. Правильно обученный бот будет играть как минимакс бот, а то и лучше. Очень много времени занимает его процесс обучения, но процесс происходит всего один раз. В отличии от минимакс бота, очень быстро будут проходить рассчёты даже на ОГРОМНЫХ игровых полях. Сам процесс обучения бота затянулся, время, потраченное на подбор правильных настроек, превысило все остальные работы примерно в два раза, что говорит о комплексности вопроса о нейросетях и о том, что этому вопросу стоит уделить больше внимания.
